{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from huggingface_hub import snapshot_download\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_percentage_error, mean_absolute_error, r2_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "4726978f375f6eed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Wczytanie danych",
   "id": "37a6b29b57020bb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # 1. Download dataset repo\n",
    "# local_dir = snapshot_download(\n",
    "#     repo_id=\"ejhusom/llm-inference-energy-consumption\",\n",
    "#     repo_type=\"dataset\",\n",
    "# )\n",
    "#\n",
    "# # 2. Point to folder with CSVs\n",
    "# data_dir = os.path.join(local_dir, \"data\")\n",
    "#\n",
    "# # 3. Read and label each CSV\n",
    "# dfs = []\n",
    "# for path in glob.glob(os.path.join(data_dir, \"*.csv\")):\n",
    "#     fname = os.path.basename(path)\n",
    "#     print(\"Reading:\", fname)\n",
    "#\n",
    "#     # infer label: laptop or workstation\n",
    "#     if \"laptop1\" in fname.lower():\n",
    "#         device_type = \"laptop1\"\n",
    "#     if \"laptop2\" in fname.lower():\n",
    "#         device_type = \"laptop2\"\n",
    "#     elif \"workstation\" in fname.lower():\n",
    "#         device_type = \"workstation\"\n",
    "#     elif \"server\" in fname.lower():\n",
    "#         device_type = \"server\"\n",
    "#     else:\n",
    "#         device_type = \"unknown\"\n",
    "#\n",
    "#     df = pd.read_csv(path)\n",
    "#     df[\"device_type\"] = device_type   # add as a new column\n",
    "#     dfs.append(df)\n",
    "#\n",
    "# # 4. Merge all CSVs\n",
    "# full_df = pd.concat(dfs, ignore_index=True)\n",
    "#\n",
    "# # 5. Save merged version\n",
    "# if not os.path.exists(\"data\"):\n",
    "#     os.mkdir(\"data\")\n",
    "# full_df.to_csv(os.path.join(\"data\", \"llm_inference_energy.csv\"), index=False)\n",
    "#\n",
    "# print(\"✅ Combined shape:\", full_df.shape)\n",
    "# print(\"✅ Unique device types:\", full_df[\"device_type\"].unique())"
   ],
   "id": "6684d2be7732918",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(os.path.join(\"data/llm_inference_energy.csv\"))\n",
    "\n",
    "data.info()"
   ],
   "id": "bb17cb61d406aa7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "More spec columns",
   "id": "2ec603cd5750a96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device_specs = {\n",
    "    \"server\": {\n",
    "        \"cpu_vendor\": \"AMD\",\n",
    "        \"cpu_family\": \"EPYC 7643\",\n",
    "        \"cpu_cores\": 48,\n",
    "        \"cpu_base_clock_ghz\": np.nan,  # unknown from your string; fill later if needed\n",
    "        \"ram_gb\": 528,\n",
    "        \"has_gpu\": 1,\n",
    "        \"gpu_model\": \"RTX A5000\",\n",
    "        \"gpu_vram_gb\": 24,\n",
    "        \"gpu_class\": \"pro\",\n",
    "        \"device_family\": \"server\",\n",
    "        \"is_mobile\": 0,\n",
    "    },\n",
    "    \"workstation\": {\n",
    "        \"cpu_vendor\": \"Intel\",\n",
    "        \"cpu_family\": \"Xeon W-2223\",\n",
    "        \"cpu_cores\": 8,\n",
    "        \"cpu_base_clock_ghz\": 3.6,\n",
    "        \"ram_gb\": 128,\n",
    "        \"has_gpu\": 1,\n",
    "        \"gpu_model\": \"RTX A2000\",\n",
    "        \"gpu_vram_gb\": 12,\n",
    "        \"gpu_class\": \"pro\",\n",
    "        \"device_family\": \"workstation\",\n",
    "        \"is_mobile\": 0,\n",
    "    },\n",
    "    \"laptop1\": {\n",
    "        \"cpu_vendor\": \"Intel\",\n",
    "        \"cpu_family\": \"Core i5 11th Gen\",\n",
    "        \"cpu_cores\": 12,\n",
    "        \"cpu_base_clock_ghz\": 2.4,\n",
    "        \"ram_gb\": 16,\n",
    "        \"has_gpu\": 0,\n",
    "        \"gpu_model\": \"None\",\n",
    "        \"gpu_vram_gb\": 0,\n",
    "        \"gpu_class\": \"none\",\n",
    "        \"device_family\": \"laptop\",\n",
    "        \"is_mobile\": 1,\n",
    "    },\n",
    "    \"laptop2\": {\n",
    "        \"cpu_vendor\": \"Intel\",\n",
    "        \"cpu_family\": \"Core i7 10th Gen\",\n",
    "        \"cpu_cores\": 12,\n",
    "        \"cpu_base_clock_ghz\": 2.7,\n",
    "        \"ram_gb\": 32,\n",
    "        \"has_gpu\": 1,\n",
    "        \"gpu_model\": \"Quadro RTX 4000\",\n",
    "        \"gpu_vram_gb\": 8,\n",
    "        \"gpu_class\": \"pro\",\n",
    "        \"device_family\": \"laptop\",\n",
    "        \"is_mobile\": 1,\n",
    "    },\n",
    "}\n",
    "\n",
    "data[\"device_spec\"] = data[\"device_type\"].map(device_specs)\n",
    "data = data.join(pd.json_normalize(data[\"device_spec\"]))\n",
    "data.drop(columns=[\"device_spec\"], inplace=True)\n",
    "\n",
    "data.head()"
   ],
   "id": "c791a06d601cb87a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Proper model names",
   "id": "90fb770d1b9d827d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rename_map = {\n",
    "    \"codellama\": \"codellama:7b\",\n",
    "    \"llama3\": \"llama3:8b\",\n",
    "}\n",
    "\n",
    "data['model_name'] = data['model_name'].replace(rename_map)"
   ],
   "id": "71c0bbca548d914b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get model param number",
   "id": "2d237d2a2cad1275"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param_map = {\n",
    "    \"gemma:2b\":       2e9,\n",
    "    \"gemma:7b\":       7e9,\n",
    "    \"codellama:7b\":   7e9,\n",
    "    \"llama3:8b\":      8e9,\n",
    "    \"llama3:70b\":     70e9,\n",
    "    \"codellama:70b\":  70e9,\n",
    "}\n",
    "\n",
    "data[\"model_params\"] = data[\"model_name\"].map(param_map).astype(float)  # number of parameters\n",
    "data[\"model_params_billion\"] = data[\"model_params\"] / 1e9"
   ],
   "id": "1747cc3aec8e239a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data[\"model_name\"]",
   "id": "3ad66022038f7fa6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Level of prompt complexity",
   "id": "9b5e3128b9894d8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data[\"readability_min_grade\"] = data[\"text_standard\"].str.split(\" \").str[0].str.replace(\"th|st|nd|rd\", \"\", regex=True).astype(float)\n",
    "data[\"readability_max_grade\"] = data[\"text_standard\"].str.split(\" and \").str[1].str.split(\" \").str[0].str.replace(\"th|st|nd|rd\", \"\", regex=True).astype(float)\n",
    "data[\"readability_diff\"] = data[\"readability_max_grade\"] - data[\"readability_min_grade\"]"
   ],
   "id": "72adc84fc7dc6d7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prepare_data(dataframe: pd.DataFrame):\n",
    "    basic_columns = [\"Unnamed: 0.2\", \"Unnamed: 0.1\", \"Unnamed: 0\", \"index\", \"created_at\", \"start_time\", \"end_time\", \"energy_consumption_llm_total\", \"type\", \"energy_consumption_monitoring\", \"response\", \"prompt\", \"text_standard\", \"energy_consumption_llm_gpu\", \"energy_consumption_llm_cpu\"]\n",
    "    basic_columns = list(set(basic_columns) & set(dataframe.columns))\n",
    "    dataframe.drop(columns=basic_columns, inplace=True)\n",
    "    dataframe = dataframe.loc[~dataframe[\"model_name\"].isin([\"llama3:70b\", \"codellama:70b\"])].reset_index(drop=True)\n",
    "    target_corr = data.corr(numeric_only=True)[\"energy_consumption_llm\"].to_frame()\n",
    "\n",
    "    low_correlated = target_corr.loc[\n",
    "        (target_corr[\"energy_consumption_llm\"] >= -0.01) &\n",
    "        (target_corr[\"energy_consumption_llm\"] <= 0.01)\n",
    "    ].index\n",
    "\n",
    "    dataframe = dataframe.drop(columns=low_correlated)\n",
    "\n",
    "    return dataframe"
   ],
   "id": "1c356f9605631ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Column groups",
   "id": "59b8ab138d62d8bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prompt_columns = [\n",
    "    'prompt', 'word_count', 'sentence_count', 'avg_word_length',\n",
    "    'word_diversity', 'unique_word_count', 'avg_sentence_length',\n",
    "    'punctuation_count', 'stop_word_count', 'long_word_count',\n",
    "    'named_entity_count', 'noun_count', 'verb_count', 'adj_count',\n",
    "    'adverb_count', 'pronoun_count', 'prop_adverbs', 'prop_pronouns',\n",
    "    'sentiment_polarity', 'sentiment_subjectivity', 'flesch_reading_ease',\n",
    "    'flesch_kincaid_grade', 'gunning_fog', 'smog_index',\n",
    "    'automated_readability_index', 'coleman_liau_index',\n",
    "    'linsear_write_formula', 'dale_chall_readability_score',\n",
    "    'text_standard', 'spache_readability', 'mcalpine_eflaw', 'reading_time',\n",
    "    'fernandez_huerta', 'szigriszt_pazos', 'gutierrez_polini', 'crawford',\n",
    "    'osman', 'gulpease_index', 'wiener_sachtextformel', 'syllable_count',\n",
    "    'lexicon_count', 'char_count', 'letter_count', 'polysyllabcount',\n",
    "    'monosyllabcount', 'question_marks', 'exclamation_marks',\n",
    "    'sentence_embedding_variance', 'personal_pronouns', 'named_entities',\n",
    "    'adjectives', 'adverbs', 'length_x_complexity',\n",
    "    'questions_about_entities', 'desc_complexity_ratio',\n",
    "    'word_count_squared', 'avg_sentence_length_cubed', 'lexical_diversity'\n",
    "]\n",
    "hardware_model_columns = ['device_type', 'cpu_vendor', 'cpu_family', 'cpu_cores', 'cpu_base_clock_ghz', 'ram_gb', 'has_gpu', 'gpu_model', 'gpu_vram_gb', 'gpu_class', 'device_family', 'is_mobile', 'model_name', 'model_params', 'model_params_billion']\n",
    "response_columns = [_ for _ in data.columns if _ not in prompt_columns and _ not in hardware_model_columns]"
   ],
   "id": "ba78f5f75945137f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Train/valid/test",
   "id": "577a86556e052b56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = prepare_data(data)\n",
    "\n",
    "data[\"strata\"] = data[\"model_name\"].astype(str) + \"__\" + data[\"device_type\"].astype(str)\n",
    "\n",
    "train, test = train_test_split(\n",
    "    data,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=data[\"strata\"]\n",
    ")\n",
    "\n",
    "# Usuń pomocniczą kolumnę\n",
    "train = train.drop(columns=[\"strata\"])\n",
    "test = test.drop(columns=[\"strata\"])"
   ],
   "id": "12289484f8dd5849",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Get metrics",
   "id": "4524d7d039fd5288"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def get_metrics(y_true, y_pred) -> dict:\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return dict(zip([\"rmse\", \"mape\", \"mae\", \"r2\"], [rmse, mape, mae, r2]))\n",
    "\n",
    "def smape(y_true, y_pred, epsilon = 1e-8):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) + epsilon\n",
    "\n",
    "    return 100 * np.mean(numerator / denominator)\n",
    "\n",
    "smape_scorer = make_scorer(smape, greater_is_better=False)"
   ],
   "id": "34d65017f439698c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### <center>Basic dataset</center>",
   "id": "5e9187929b6369f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "categories = [col for col in train.columns if train[col].dtype == \"object\"]\n",
    "whole_X_train_basic, whole_y_train_basic = train.drop(columns=[\"energy_consumption_llm\"]), train[\"energy_consumption_llm\"]"
   ],
   "id": "421cdb2db6898c7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "whole_y_train_basic.describe()",
   "id": "5fa18a1626f8c247",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "whole_X_train_basic[categories] = whole_X_train_basic[categories].astype(\"category\")\n",
    "# whole_y_train_basic = np.log1p(whole_y_train_basic)\n",
    "\n",
    "X_train_basic, X_test_basic, y_train_basic, y_test_basic = train_test_split(whole_X_train_basic, whole_y_train_basic, test_size=0.3, random_state=42)"
   ],
   "id": "e69d29b442b329d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "whole_y_train_basic.describe()",
   "id": "283b9344d1a184cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.hist(whole_y_train_basic, bins=50)\n",
    "plt.title('Original Distribution')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.hist(np.log(whole_y_train_basic), bins=50)\n",
    "plt.yscale('log')\n",
    "plt.title('Log Scale Y-axis')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.boxplot(whole_y_train_basic)\n",
    "plt.title('Boxplot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check outliers\n",
    "print(f\"99th percentile: {np.percentile(whole_y_train_basic, 99):.6f}\")\n",
    "print(f\"99.9th percentile: {np.percentile(whole_y_train_basic, 99.9):.6f}\")"
   ],
   "id": "a7f248e027393917",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "upper_limit = y_train_basic.quantile(0.99)\n",
    "print(f\"Clipping outliers at 99th percentile: {upper_limit:.6f}\")\n",
    "print(f\"Original max: {y_train_basic.max():.6f}\")\n",
    "print(f\"Values being clipped: {(y_train_basic > upper_limit).sum()} out of {len(y_train_basic)}\")"
   ],
   "id": "b842034d03689d50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. LightGBM",
   "id": "c1713cdd150df8a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_train_clipped = y_train_basic.clip(upper=upper_limit)\n",
    "\n",
    "\n",
    "def define_lgb(trial: optuna.Trial) -> lgb.LGBMRegressor:\n",
    "    params = {\n",
    "        # Regularyzacja\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.01, 5, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.01, 5, log=True),\n",
    "\n",
    "        # Learning\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.15, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "\n",
    "        # Tree structure\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 48),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 10, 80),\n",
    "\n",
    "        # Sampling\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"subsample_freq\": 1,\n",
    "\n",
    "        # Quantile regression (mediana - odporna na outliery)\n",
    "        \"objective\": \"quantile\",\n",
    "        \"alpha\": 0.5,  # 0.5 = mediana\n",
    "\n",
    "        \"random_state\": 42,\n",
    "        \"boosting\": \"gbdt\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "    return lgb.LGBMRegressor(**params)\n",
    "\n",
    "\n",
    "def optimize_lightgbm_basic(trial: optuna.Trial):\n",
    "    lightgbm = define_lgb(trial)\n",
    "    groups = X_train_basic[\"model_name\"]\n",
    "    kf = GroupKFold(\n",
    "        n_splits=len(np.unique(groups)),\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        lightgbm,\n",
    "        X_train_basic,\n",
    "        y_train_clipped,\n",
    "        cv=kf,\n",
    "        groups=groups,\n",
    "        scoring='neg_root_mean_squared_error'\n",
    "    )\n",
    "    return scores.mean() * (-1)\n",
    "\n",
    "\n",
    "study_lgb_basic = optuna.create_study(\n",
    "    study_name=\"Optimize LGBM\",\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    ")\n",
    "\n",
    "study_lgb_basic.optimize(optimize_lightgbm_basic, n_trials=100)"
   ],
   "id": "28013cdee6c5a0a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### KROK 3: Po optymalizacji, wytrenuj finalny model",
   "id": "fe83ae93065549f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Finalny model z najlepszymi parametrami\n",
    "best_params = study_lgb_basic.best_params\n",
    "best_params.update({\n",
    "    \"random_state\": 42,\n",
    "    \"objective\": \"quantile\",\n",
    "    \"alpha\": 0.5,\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbose\": -1,\n",
    "})\n",
    "\n",
    "final_model = lgb.LGBMRegressor(**best_params)\n",
    "final_model.fit(X_train_basic, y_train_clipped)"
   ],
   "id": "b2f82808f34ae66b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"\\nBest parameters:\", study_lgb_basic.best_params)",
   "id": "b5da177b0e0cd3a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### KROK 4: Predykcja i ewaluacja",
   "id": "189b38567e93596f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions = final_model.predict(X_test_basic)\n",
    "\n",
    "metrics = get_metrics(y_test_basic, predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL MODEL EVALUATION (on original test data)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MAE:  {metrics[\"mae\"]:.6f} (relative: {metrics[\"mae\"] / y_test_basic.mean():.2%})\")\n",
    "print(f\"RMSE: {metrics[\"rmse\"]:.6f}\")\n",
    "print(f\"R²:   {metrics[\"r2\"]:.4f}\")\n",
    "print(f\"\\nTest set mean: {y_test_basic.mean():.6f}\")\n",
    "print(f\"Test set std:  {y_test_basic.std():.6f}\")"
   ],
   "id": "64f585017654e310",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Analiza błędów na outlierach",
   "id": "b95543cf70296c94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "errors = np.abs(y_test_basic - predictions)\n",
    "outlier_mask = y_test_basic > upper_limit\n",
    "\n",
    "test_metrics_without_outliers = get_metrics(y_test_basic[~outlier_mask], predictions[~outlier_mask])\n",
    "test_metrics_with_outliers = get_metrics(y_test_basic[outlier_mask], predictions[outlier_mask])\n",
    "print(f\"\\n{'Metric':<20} {'All Test':<15} {'Non-outliers':<15} {'Outliers':<15}\")\n",
    "print(\"-\"*65)\n",
    "print(f\"{'Count':<20} {len(y_test_basic):<15} {(~outlier_mask).sum():<15} {outlier_mask.sum():<15}\")\n",
    "print(f\"{'MAE':<20} {mae:.6f}       {test_metrics_without_outliers[\"mae\"]:.6f}       {test_metrics_with_outliers[\"mae\"]:.6f}\")\n",
    "print(f\"{'RMSE':<20} {rmse:.6f}       {test_metrics_without_outliers[\"rmse\"]:.6f}       {test_metrics_with_outliers[\"rmse\"]:.6f}\")\n",
    "print(f\"{'R²':<20} {r2:.4f}          {test_metrics_without_outliers[\"r2\"]:.4f}          {test_metrics_with_outliers[\"r2\"]:.4f}\")"
   ],
   "id": "2ab352378c031465",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lightGBM_importance = pd.DataFrame({\n",
    "    'feature': final_model.feature_name_,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "ax = sns.barplot(\n",
    "    data=lightGBM_importance,\n",
    "    x='importance',\n",
    "    y='feature',\n",
    "    hue='feature',\n",
    "    legend=False,\n",
    "    palette='viridis'\n",
    ")\n",
    "\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i, fmt='%g', label_type='edge', fontsize=10, padding=3)\n",
    "\n",
    "plt.title('10 the most important columns for LightGBM', fontsize=16)\n",
    "plt.xlabel('Importance value', fontsize=12)\n",
    "plt.ylabel('Column', fontsize=12)\n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "89e0049c5c411092",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Learning curve",
   "id": "5d13c1b4d21cd3d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "groups = X_train_basic[\"model_name\"]\n",
    "kf = GroupKFold(\n",
    "    n_splits=len(np.unique(groups)),\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_sizes, train_scores, valid_scores = learning_curve(\n",
    "    final_model,\n",
    "    X_train_basic,\n",
    "    y_train_clipped,\n",
    "    cv=kf,\n",
    "    groups=groups,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    train_sizes=np.linspace(0.1, 1.0, 6),\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "train_scores = -train_scores\n",
    "valid_scores = -valid_scores\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), \"o-\", label=\"Train RMSE\")\n",
    "plt.plot(train_sizes, valid_scores.mean(axis=1), \"o-\", label=\"Valid RMSE\")\n",
    "plt.fill_between(train_sizes,\n",
    "                 train_scores.mean(axis=1) - train_scores.std(axis=1),\n",
    "                 train_scores.mean(axis=1) + train_scores.std(axis=1),\n",
    "                 alpha=0.2)\n",
    "plt.fill_between(train_sizes,\n",
    "                 valid_scores.mean(axis=1) - valid_scores.std(axis=1),\n",
    "                 valid_scores.mean(axis=1) + valid_scores.std(axis=1),\n",
    "                 alpha=0.2)\n",
    "\n",
    "plt.title(\"Learning Curve (RMSE)\")\n",
    "plt.xlabel(\"Training samples\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "51c863803c45bad6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### <center>Optuna visualization</center>",
   "id": "c7c8fdab8b5df785"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_optimization_history(study_lgb_basic)",
   "id": "a3f50e315cfdd1b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_slice(study_lgb_basic)",
   "id": "14c93c5bc2fff242",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_param_importances(study_lgb_basic)",
   "id": "11be4ecdda5f1214",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save model to file and read it",
   "id": "3b8808dc6095184b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "def save_model(model: lgb.LGBMRegressor, filename: str):\n",
    "    if not os.path.exists(\"models\"):\n",
    "        os.mkdir(\"models\")\n",
    "    joblib.dump(model, os.path.join(\"models\", filename))\n",
    "\n",
    "def get_model(filename: str) -> lgb.LGBMRegressor:\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(f\"Brak zapisanego modelu o podanej nazwie {filename}\")\n",
    "\n",
    "    return joblib.load(filename)\n",
    "\n",
    "def predict(model_name: str, x_test: np.typing.NDArray[np.float64]) -> np.typing.NDArray[np.float64]:\n",
    "    if not os.path.exists(os.path.join(\"models\", model_name)):\n",
    "        raise FileNotFoundError(f\"Brak zapisanego modelu o podanej nazwie {model_name}\")\n",
    "\n",
    "    model = get_model(model_name)\n",
    "    return model.predict(x_test)"
   ],
   "id": "9f76a46b58729a24",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
