{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from huggingface_hub import snapshot_download\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_percentage_error, mean_absolute_error, r2_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "4726978f375f6eed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Wczytanie danych",
   "id": "37a6b29b57020bb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. Download dataset repo\n",
    "local_dir = snapshot_download(\n",
    "    repo_id=\"ejhusom/llm-inference-energy-consumption\",\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "\n",
    "# 2. Point to folder with CSVs\n",
    "data_dir = os.path.join(local_dir, \"data\")\n",
    "\n",
    "# 3. Read and label each CSV\n",
    "dfs = []\n",
    "for path in glob.glob(os.path.join(data_dir, \"*.csv\")):\n",
    "    fname = os.path.basename(path)\n",
    "    print(\"Reading:\", fname)\n",
    "\n",
    "    # infer label: laptop or workstation\n",
    "    if \"laptop1\" in fname.lower():\n",
    "        device_type = \"laptop1\"\n",
    "    if \"laptop2\" in fname.lower():\n",
    "        device_type = \"laptop2\"\n",
    "    elif \"workstation\" in fname.lower():\n",
    "        device_type = \"workstation\"\n",
    "    elif \"server\" in fname.lower():\n",
    "        device_type = \"server\"\n",
    "    else:\n",
    "        device_type = \"unknown\"\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"device_type\"] = device_type   # add as a new column\n",
    "    dfs.append(df)\n",
    "\n",
    "# 4. Merge all CSVs\n",
    "full_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# 5. Save merged version\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "full_df.to_csv(os.path.join(\"data\", \"llm_inference_energy.csv\"), index=False)\n",
    "\n",
    "print(\"✅ Combined shape:\", full_df.shape)\n",
    "print(\"✅ Unique device types:\", full_df[\"device_type\"].unique())"
   ],
   "id": "6684d2be7732918",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(os.path.join(\"data/llm_inference_energy.csv\"))\n",
    "\n",
    "data.info()"
   ],
   "id": "bb17cb61d406aa7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "More spec columns",
   "id": "2ec603cd5750a96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device_specs = {\n",
    "    \"server\": {\n",
    "        \"cpu_vendor\": \"AMD\",\n",
    "        \"cpu_family\": \"EPYC 7643\",\n",
    "        \"cpu_cores\": 48,\n",
    "        \"cpu_base_clock_ghz\": np.nan,  # unknown from your string; fill later if needed\n",
    "        \"ram_gb\": 528,\n",
    "        \"has_gpu\": 1,\n",
    "        \"gpu_model\": \"RTX A5000\",\n",
    "        \"gpu_vram_gb\": 24,\n",
    "        \"gpu_class\": \"pro\",\n",
    "        \"device_family\": \"server\",\n",
    "        \"is_mobile\": 0,\n",
    "    },\n",
    "    \"workstation\": {\n",
    "        \"cpu_vendor\": \"Intel\",\n",
    "        \"cpu_family\": \"Xeon W-2223\",\n",
    "        \"cpu_cores\": 8,\n",
    "        \"cpu_base_clock_ghz\": 3.6,\n",
    "        \"ram_gb\": 128,\n",
    "        \"has_gpu\": 1,\n",
    "        \"gpu_model\": \"RTX A2000\",\n",
    "        \"gpu_vram_gb\": 12,\n",
    "        \"gpu_class\": \"pro\",\n",
    "        \"device_family\": \"workstation\",\n",
    "        \"is_mobile\": 0,\n",
    "    },\n",
    "    \"laptop1\": {\n",
    "        \"cpu_vendor\": \"Intel\",\n",
    "        \"cpu_family\": \"Core i5 11th Gen\",\n",
    "        \"cpu_cores\": 12,\n",
    "        \"cpu_base_clock_ghz\": 2.4,\n",
    "        \"ram_gb\": 16,\n",
    "        \"has_gpu\": 0,\n",
    "        \"gpu_model\": \"None\",\n",
    "        \"gpu_vram_gb\": 0,\n",
    "        \"gpu_class\": \"none\",\n",
    "        \"device_family\": \"laptop\",\n",
    "        \"is_mobile\": 1,\n",
    "    },\n",
    "    \"laptop2\": {\n",
    "        \"cpu_vendor\": \"Intel\",\n",
    "        \"cpu_family\": \"Core i7 10th Gen\",\n",
    "        \"cpu_cores\": 12,\n",
    "        \"cpu_base_clock_ghz\": 2.7,\n",
    "        \"ram_gb\": 32,\n",
    "        \"has_gpu\": 1,\n",
    "        \"gpu_model\": \"Quadro RTX 4000\",\n",
    "        \"gpu_vram_gb\": 8,\n",
    "        \"gpu_class\": \"pro\",\n",
    "        \"device_family\": \"laptop\",\n",
    "        \"is_mobile\": 1,\n",
    "    },\n",
    "}\n",
    "\n",
    "data[\"device_spec\"] = data[\"device_type\"].map(device_specs)\n",
    "data = data.join(pd.json_normalize(data[\"device_spec\"]))\n",
    "data.drop(columns=[\"device_spec\"], inplace=True)\n",
    "\n",
    "data.head()"
   ],
   "id": "c791a06d601cb87a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Proper model names",
   "id": "90fb770d1b9d827d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rename_map = {\n",
    "    \"codellama\": \"codellama:7b\",\n",
    "    \"llama3\": \"llama3:8b\",\n",
    "}\n",
    "\n",
    "data['model_name'] = data['model_name'].replace(rename_map)"
   ],
   "id": "71c0bbca548d914b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get model param number",
   "id": "2d237d2a2cad1275"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param_map = {\n",
    "    \"gemma:2b\":       2e9,\n",
    "    \"gemma:7b\":       7e9,\n",
    "    \"codellama:7b\":   7e9,\n",
    "    \"llama3:8b\":      8e9,\n",
    "    \"llama3:70b\":     70e9,\n",
    "    \"codellama:70b\":  70e9,\n",
    "}\n",
    "\n",
    "data[\"model_params\"] = data[\"model_name\"].map(param_map).astype(float)  # number of parameters\n",
    "data[\"model_params_billion\"] = data[\"model_params\"] / 1e9"
   ],
   "id": "3ad66022038f7fa6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Level of prompt complexity",
   "id": "9b5e3128b9894d8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data[\"readability_min_grade\"] = data[\"text_standard\"].str.split(\" \").str[0].str.replace(\"th|st|nd|rd\", \"\", regex=True).astype(float)\n",
    "data[\"readability_max_grade\"] = data[\"text_standard\"].str.split(\" and \").str[1].str.split(\" \").str[0].str.replace(\"th|st|nd|rd\", \"\", regex=True).astype(float)\n",
    "data[\"readability_diff\"] = data[\"readability_max_grade\"] - data[\"readability_min_grade\"]"
   ],
   "id": "72adc84fc7dc6d7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prepare_data(dataframe: pd.DataFrame):\n",
    "    basic_columns = [\"Unnamed: 0.2\", \"Unnamed: 0.1\", \"Unnamed: 0\", \"index\", \"created_at\", \"start_time\", \"end_time\", \"energy_consumption_llm_total\", \"type\", \"energy_consumption_monitoring\", \"response\", \"prompt\", \"text_standard\", \"energy_consumption_llm_gpu\", \"energy_consumption_llm_cpu\"]\n",
    "    basic_columns = list(set(basic_columns) & set(dataframe.columns))\n",
    "    dataframe.drop(columns=basic_columns, inplace=True)\n",
    "    dataframe = dataframe.loc[~dataframe[\"model_name\"].isin([\"llama3:70b\", \"codellama:70b\"])].reset_index(drop=True)\n",
    "    return dataframe"
   ],
   "id": "1c356f9605631ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Column groups",
   "id": "59b8ab138d62d8bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prompt_columns = [\n",
    "    'prompt', 'word_count', 'sentence_count', 'avg_word_length',\n",
    "    'word_diversity', 'unique_word_count', 'avg_sentence_length',\n",
    "    'punctuation_count', 'stop_word_count', 'long_word_count',\n",
    "    'named_entity_count', 'noun_count', 'verb_count', 'adj_count',\n",
    "    'adverb_count', 'pronoun_count', 'prop_adverbs', 'prop_pronouns',\n",
    "    'sentiment_polarity', 'sentiment_subjectivity', 'flesch_reading_ease',\n",
    "    'flesch_kincaid_grade', 'gunning_fog', 'smog_index',\n",
    "    'automated_readability_index', 'coleman_liau_index',\n",
    "    'linsear_write_formula', 'dale_chall_readability_score',\n",
    "    'text_standard', 'spache_readability', 'mcalpine_eflaw', 'reading_time',\n",
    "    'fernandez_huerta', 'szigriszt_pazos', 'gutierrez_polini', 'crawford',\n",
    "    'osman', 'gulpease_index', 'wiener_sachtextformel', 'syllable_count',\n",
    "    'lexicon_count', 'char_count', 'letter_count', 'polysyllabcount',\n",
    "    'monosyllabcount', 'question_marks', 'exclamation_marks',\n",
    "    'sentence_embedding_variance', 'personal_pronouns', 'named_entities',\n",
    "    'adjectives', 'adverbs', 'length_x_complexity',\n",
    "    'questions_about_entities', 'desc_complexity_ratio',\n",
    "    'word_count_squared', 'avg_sentence_length_cubed', 'lexical_diversity'\n",
    "]\n",
    "hardware_model_columns = ['device_type', 'cpu_vendor', 'cpu_family', 'cpu_cores', 'cpu_base_clock_ghz', 'ram_gb', 'has_gpu', 'gpu_model', 'gpu_vram_gb', 'gpu_class', 'device_family', 'is_mobile', 'model_name', 'model_params', 'model_params_billion']\n",
    "response_columns = [_ for _ in data.columns if _ not in prompt_columns and _ not in hardware_model_columns]"
   ],
   "id": "ba78f5f75945137f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Train/valid/test",
   "id": "577a86556e052b56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = prepare_data(data)\n",
    "\n",
    "data[\"strata\"] = data[\"model_name\"].astype(str) + \"__\" + data[\"device_type\"].astype(str)\n",
    "\n",
    "train, test = train_test_split(\n",
    "    data,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=data[\"strata\"]\n",
    ")\n",
    "\n",
    "# Usuń pomocniczą kolumnę\n",
    "train = train.drop(columns=[\"strata\"])\n",
    "test = test.drop(columns=[\"strata\"])"
   ],
   "id": "12289484f8dd5849",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Get metrics",
   "id": "4524d7d039fd5288"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def get_metrics(y_true, y_pred) -> dict:\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return dict(zip([\"rmse\", \"mape\", \"mae\", \"r2\"], [rmse, mape, mae, r2]))\n",
    "\n",
    "def smape(y_true, y_pred, epsilon = 1e-8):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) + epsilon\n",
    "\n",
    "    return 100 * np.mean(numerator / denominator)\n",
    "\n",
    "smape_scorer = make_scorer(smape, greater_is_better=False)"
   ],
   "id": "34d65017f439698c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### <center>Basic dataset</center>",
   "id": "5e9187929b6369f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "categories = [col for col in train.columns if train[col].dtype == \"object\"]\n",
    "whole_X_train_basic, whole_y_train_basic = train.drop(columns=[\"energy_consumption_llm\"]), train[\"energy_consumption_llm\"]"
   ],
   "id": "421cdb2db6898c7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "whole_y_train_basic.describe()",
   "id": "5fa18a1626f8c247",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "whole_X_train_basic[categories] = whole_X_train_basic[categories].astype(\"category\")\n",
    "# whole_y_train_basic = np.log1p(whole_y_train_basic)\n",
    "\n",
    "X_train_basic, X_test_basic, y_train_basic, y_test_basic = train_test_split(whole_X_train_basic, whole_y_train_basic, test_size=0.3, random_state=42)"
   ],
   "id": "e69d29b442b329d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "whole_y_train_basic.describe()",
   "id": "283b9344d1a184cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. LightGBM",
   "id": "c1713cdd150df8a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def define_lgb(trial: optuna.Trial) -> lgb.LGBMRegressor:\n",
    "    params = {\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 1, log=True),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-2, 1, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 150),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 64),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 8, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 3, 50),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.7, 1.0),\n",
    "        \"random_state\": 42,\n",
    "        \"objective\": \"regression\",\n",
    "        \"boosting\": \"gbdt\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "    return lgb.LGBMRegressor(**params)\n",
    "\n",
    "\n",
    "def optimize_lightgbm_basic(trial: optuna.Trial):\n",
    "    lightgbm = define_lgb(trial)\n",
    "    groups = X_train_basic[\"model_name\"]\n",
    "    kf = GroupKFold(\n",
    "        n_splits=len(np.unique(groups)),\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    scores = cross_val_score(\n",
    "        lightgbm,\n",
    "        X_train_basic,\n",
    "        y_train_basic,\n",
    "        cv=kf,\n",
    "        groups=groups,\n",
    "        scoring='neg_root_mean_squared_error'\n",
    "    )\n",
    "    return scores.mean() * (-1)\n",
    "\n",
    "\n",
    "study_lgb_basic = optuna.create_study(\n",
    "    study_name=\"Optimize LGBM\",\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    ")\n",
    "\n",
    "study_lgb_basic.optimize(optimize_lightgbm_basic, n_trials=10)"
   ],
   "id": "bb72365223f2f65b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### <center>Optuna visualization</center>",
   "id": "c7c8fdab8b5df785"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_optimization_history(study_lgb_basic)",
   "id": "a3f50e315cfdd1b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_slice(study_lgb_basic)",
   "id": "14c93c5bc2fff242",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_param_importances(study_lgb_basic)",
   "id": "11be4ecdda5f1214",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save model to file and read it",
   "id": "3b8808dc6095184b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "def save_model(model: lgb.LGBMRegressor, filename: str):\n",
    "    if not os.path.exists(\"models\"):\n",
    "        os.mkdir(\"models\")\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "def get_model(filename: str) -> lgb.LGBMRegressor:\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(f\"Brak zapisanego modelu o podanej nazwie {filename}\")\n",
    "\n",
    "    return joblib.load(filename)\n",
    "\n",
    "def predict(model_name: str, x_test: np.typing.NDArray[np.float64]) -> np.typing.NDArray[np.float64]:\n",
    "    if not os.path.exists(os.path.join(\"models\", model_name)):\n",
    "        raise FileNotFoundError(f\"Brak zapisanego modelu o podanej nazwie {model_name}\")\n",
    "\n",
    "    model = get_model(model_name)\n",
    "    return model.predict(x_test)"
   ],
   "id": "9f76a46b58729a24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Best LightGBM",
   "id": "e67103bed7417ed3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lightGBM_basic = define_lgb(study_lgb_basic.best_trial).fit(X_train_basic, y_train_basic)\n",
    "save_model(lightGBM_basic, \"lgb.pkl\")\n",
    "get_metrics(y_test_basic, lightGBM_basic.predict(X_test_basic))"
   ],
   "id": "7e73cbca05c46486"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "study_lgb_basic.best_params",
   "id": "1676b44066228f97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lightGBM_basic_importance = pd.DataFrame({\n",
    "    'feature': lightGBM_basic.feature_name_,\n",
    "    'importance': lightGBM_basic.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "ax = sns.barplot(\n",
    "    data=lightGBM_basic_importance,\n",
    "    x='importance',\n",
    "    y='feature',\n",
    "    hue='feature',\n",
    "    legend=False,\n",
    "    palette='viridis'\n",
    ")\n",
    "\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i, fmt='%g', label_type='edge', fontsize=10, padding=3)\n",
    "\n",
    "plt.title('10 the most important columns for LightGBM', fontsize=16)\n",
    "plt.xlabel('Importance value', fontsize=12)\n",
    "plt.ylabel('Column', fontsize=12)\n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c4b115afef41837d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. XGBoost",
   "id": "1bffbd9f22b586e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def define_xgb(trial: optuna.Trial) -> xgb.XGBRegressor:\n",
    "    params = {\n",
    "        'tree_method': 'hist',\n",
    "        'enable_categorical': True,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 150),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-2, 1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'max_leaves': trial.suggest_int('max_leaves', 8, 48),\n",
    "        'gamma': trial.suggest_float('gamma', 0.5, 1),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 1e-1, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-2, 1, log=True),\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 256),\n",
    "        'n_jobs': -1,\n",
    "        'objective': 'reg:absoluteerror',\n",
    "        'random_state': 42\n",
    "    }\n",
    "    return xgb.XGBRegressor(**params)\n",
    "\n",
    "\n",
    "def optimize_xgb(trial: optuna.Trial):\n",
    "    xgboost = define_xgb(trial)\n",
    "    X_train_basic.drop(columns=[\"clock_duration\"], inplace=True)\n",
    "    groups = X_train_basic[\"device_type\"]\n",
    "    kf = GroupKFold(\n",
    "        n_splits=len(np.unique(groups)),\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    scores = cross_val_score(\n",
    "        xgboost,\n",
    "        X_train_basic,\n",
    "        y_train_basic,\n",
    "        cv=kf,\n",
    "        groups=X_train_basic[\"device_type\"],\n",
    "        scoring=\"neg_root_mean_squared_error\"\n",
    "    )\n",
    "    return scores.mean() * (-1)\n",
    "\n",
    "\n",
    "study_xgb = optuna.create_study(\n",
    "    study_name=\"Optimize XGBoost\",\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    ")\n",
    "\n",
    "study_xgb.optimize(optimize_xgb, n_trials=10)"
   ],
   "id": "1f3af546e7d1e489",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### <center>Optuna visualization</center>",
   "id": "5734350e3a5ae03b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_optimization_history(study_xgb)",
   "id": "c566c645b1e87a0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_slice(study_xgb)",
   "id": "141308c79fc3ac89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_param_importances(study_xgb)",
   "id": "49aaa2a38e3c4155",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Best XGBoost",
   "id": "fb7aaaf612f2f3a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xgBoost_basic = define_xgb(study_xgb.best_trial).fit(X_train_basic, y_train_basic)\n",
    "save_model(xgBoost_basic, \"models/xgBoost.pkl\")\n",
    "get_metrics(y_train_basic, xgBoost_basic.predict(X_train_basic))"
   ],
   "id": "c4c732fab1b08e37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "study_xgb.best_params",
   "id": "e42fa2c5c00531a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "importance_dict = xgBoost_basic.get_booster().get_score(importance_type='weight')\n",
    "\n",
    "xgBoost_importance = pd.DataFrame({\n",
    "    'feature': list(importance_dict.keys()),\n",
    "    'importance': list(importance_dict.values())\n",
    "}).sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "ax = sns.barplot(\n",
    "    data=xgBoost_importance,\n",
    "    x='importance',\n",
    "    y='feature',\n",
    "    hue='feature',\n",
    "    legend=False,\n",
    "    palette='viridis'\n",
    ")\n",
    "\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i, fmt='%g', label_type='edge', fontsize=10, padding=3)\n",
    "\n",
    "plt.title('10 the most important columns for XGBoost', fontsize=16)\n",
    "plt.xlabel('Importance value', fontsize=12)\n",
    "plt.ylabel('Column', fontsize=12)\n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "4c98d64e73334558",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
